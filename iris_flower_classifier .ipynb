{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb5d1ea",
   "metadata": {},
   "source": [
    "# Classification Model for Iris Dataset \n",
    "\n",
    "*Saimat Balabekova* \n",
    "<img src=\"https://www.almanac.com/sites/default/files/image_nodes/iris-flowers.jpg\" width=\"300\" height=\"auto\" style=\"border-radius:50%\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align: justify\">In this Jupyter notebook I will attempt to implement the Random Forest Algorithm on The Iris Flower Dataset using a Scikit-learn package in Python. The Iris Flower dataset comes with the Scikit-Learn package itself, meaning that it is clean enough to be used for training an ML model. This is useful for the scope of this project as it will allows me to explore the Scikit-learn package and focus on the nature of Random Forest Algorithm without spending time on obtaining, cleaning and transforming data.\n",
    "\n",
    "    \n",
    "**Objective:** To build a model that allows us to predict the type of an Iris flower based on its Petal and Sepal features such as length and width.  </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b294ab4",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e3536",
   "metadata": {},
   "source": [
    "In order to start I must begin with importing all the libraries needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8de75be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec50abf",
   "metadata": {},
   "source": [
    "Having imported the libraries, I am going to load the Iris dataset. To do so I will use *Datasets* submodule in Scikit-Learn and within it use *load_iris* fucntion:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ff0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81923e13",
   "metadata": {},
   "source": [
    "## Iris Dataset Genral Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c6c39",
   "metadata": {},
   "source": [
    "Below is the overview of the Iris Flower Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3167573c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99bb87ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iris.data)# samples of the Iris flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de33a714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names) # future input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee7ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# target_names and target represent the same information but in different formats(i.e. in str and int respectively)\n",
    "print(iris.target_names)\n",
    "print (iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d912eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe for visual scoping of the data\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'sepal length':iris.data[:,0],\n",
    "    'sepal width':iris.data[:,1],\n",
    "    'petal length':iris.data[:,2],\n",
    "    'petal width':iris.data[:,3],\n",
    "    'species':iris.target\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4a5a6",
   "metadata": {},
   "source": [
    "\n",
    "Upon the first look we can see: \n",
    "1. the *\"data\"* array which composits of a 150 flowers\n",
    "2. the *\"target\"* array that represents various class labels such as 0,1,2 \n",
    "3. the *\"target_names\"* array which correspond to the class labels above such as 'setosa', 'versicolor', 'virginica'\n",
    "\n",
    "\n",
    "Additionally, the dataset contains a list of \"feature_names\"  which represents the 4 characteristics of Iris Flower such as: \"sepal Length\"(cm),\"sepal width\"(cm); \"petal length\"(cm) and \"petal width\"(cm). \n",
    "\n",
    "Thus, **The Iris Dataset gives us 1 class output variable( i.e.\"target\"/\"target_names\") and  4 input features (i.e. \"feature_names\").** This will inform the parameters used for out Classification Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c0bbc",
   "metadata": {},
   "source": [
    "## *Input* and *Output* variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ddf18",
   "metadata": {},
   "source": [
    "For future use, let us assign **X** and **y** to be our *Input*(i.e.\"feature_names\") and to the *Output*(i.e.\"target\") variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e024e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['sepal length', 'sepal width', 'petal length', 'petal width']]  # input features\n",
    "y=df['species']  # output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7675f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "#150 rows and 4 columns for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "025bb46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n",
    "#150 rows and only 1 column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b4aa25",
   "metadata": {},
   "source": [
    "Thus **X** will contain 4 input features whereas the **y** will contain 1 feature. This makes up to a toal of 5 features over a 150 samples of Iris flowers, where each flower can be classified as either: *Iris Setosa*; *Iris Versicolor* or *Iris Virginica*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d4097",
   "metadata": {},
   "source": [
    "## *Splitting* and *Training* the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e2feb",
   "metadata": {},
   "source": [
    "I have chosen to split the dataset  into a *training set* and a *test set*. This is done for the purpose of an unbiased evaluation of prediction performance. The *Training set* is applied to fit a model whilst a *test set* is used for an independent assessment of the final model. To do so I will use the *model selection package* of scikit-learn, in particular on the function **train_test_split()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce0d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e4c02",
   "metadata": {},
   "source": [
    "The Test_Size value of 0.3 indicates to us the size of the test set. We can think of a 0.3 test size as 30%, with the remainder in this case (70%) indicating the training size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f055999f",
   "metadata": {},
   "source": [
    "## Using *Random Forest Algorithm* for Classification Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb4e913",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1280/1*9kACduxnce_JdTrftM_bsA.gif\" width=\"300\" height=\"auto\" style=\"border:50%\">\n",
    "\n",
    "To build our Classification Model I will use a *Random Forest* algorithm. \n",
    "\n",
    "Before utilising this algorithm we must first understand its basic principles. \n",
    "\n",
    "*Random Forest* algorithm is made up of many Decision Trees which operate together thereby producing a strong \"collective\" guess. When used for Classification Models, all Decision Trees in the algorithm produce a class prediction with the most commonly chosen class becoming the prediction of the overall model. \n",
    "\n",
    "Fundamentally, a *Random Forest* algorithm prediction is effective due to the *low correlation* between each class predictions produced by individual Decision Trees. In other words, each Decision Tree in a Random Forest algorithm makes up for the errors from other Trees. Although some class predictions of Decision Trees will be incorrect, a substantial number of predictions will be correct, moving the collective group of Trees in the right direction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d4d8e",
   "metadata": {},
   "source": [
    "Having covered the basic principles of a *Random Forest* algorithm, let us apply it to the Iris Flower Dataset using the **X** and **y** variables we have assigned earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8b4c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c0e23",
   "metadata": {},
   "source": [
    "The **n_estimators** above is the number of Decision Trees used for our model. The larger this number the slower the model, in this case we are using 100 Decision Trees for our *Random Forest*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568f12f",
   "metadata": {},
   "source": [
    "The Classification Model (clf) is trained using the **X** and **y** training sets created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977f747f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201865c",
   "metadata": {},
   "source": [
    "Let us create a predicted value of **y** (*i.e. y_pred*) based on the input of **X** testing set (*i.e.X-test*) using a Random Forest Predict function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5694a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f3934",
   "metadata": {},
   "source": [
    "As indicated above, our *Random Forest* generates the predicted value of y( i.e. classification of the Iris Flower) by using the predict function on the X input( i.e. the features of the Iris Flower)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65e0ab",
   "metadata": {},
   "source": [
    "## Prediction of the Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f7d35",
   "metadata": {},
   "source": [
    "Using the code from above we can input a random array of X values of our choice and predict the classification of the Iris Flower at hand. We should bear in mind that the model is using the numerical representation of the Iris Flower Class. Thus the first prediction we obtain is the number of the class. Having found the predicted numeric value of the class to which our hypothetical Iris flower belongs to, we can match it to the appropriate Class name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf3a22e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saima\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'virginica'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_species_index = clf.predict([[3,3,4,5]])[0]\n",
    "print(iris_species_index)\n",
    "\n",
    "iris.target_names[iris_species_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c16c3",
   "metadata": {},
   "source": [
    "## Evaluating the Accuracy of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cdb68e",
   "metadata": {},
   "source": [
    "To assess and calculate the accuracy of our model we will have to import *metrics* package from Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "031b8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fde224",
   "metadata": {},
   "source": [
    "Then we must use a *metrics accuracy_score* function of the y testing set( i.e. *y_test*) against the predicted y value of our model( i.e. *y_pred*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5be0592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 1, 0, 1, 1, 1, 0, 1, 0, 2, 0, 1, 1, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 2, 0, 0, 1, 2, 2, 2, 2, 2, 0, 0, 2, 1, 0, 1, 0, 0, 0]\n",
      "[2, 2, 1, 0, 1, 1, 1, 0, 1, 0, 2, 0, 1, 1, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 2, 2, 1, 2, 0, 0, 2, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(list(y_test))\n",
    "print(list(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "258b3a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e06ea",
   "metadata": {},
   "source": [
    "What the metrics accuracy_score function shows the percentage of correct predictions. This also could be simply found by a few lines of code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75955733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "total = len(y_pred)\n",
    "correct = 0\n",
    "\n",
    "for i in range(total):\n",
    "    if list(y_test)[i] == list(y_pred)[i]:\n",
    "        correct += 1\n",
    "    \n",
    "accuracy = correct / total \n",
    "print(\"Accuracy: \"+ str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87be77",
   "metadata": {},
   "source": [
    "The metrics accuracy function as well as my own calculations conclude that the accuracy of the Iris classification model is over 90%.We should note that the accuracy of the model will vary every time you run the code because of the nature of *Random Forest* algorithm. For that reason it is important to double check the *metrics.accuracy_score* function from Scikit Learn with your own calculations as I have done above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f7ae1",
   "metadata": {},
   "source": [
    "## Significant Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97db74f",
   "metadata": {},
   "source": [
    "Having evaluated the accuracy of the model we may be interested in considering which input parameters play the most significant role in determining our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "768f7427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['petal width (cm)', 'petal length (cm)', 'sepal length (cm)',\n",
       "       'sepal width (cm)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_parameters = pd.Series(clf.feature_importances_,index=iris.feature_names).sort_values(ascending=False)\n",
    "input_parameters.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a36f3",
   "metadata": {},
   "source": [
    "From the above we can see that Petal parameters (its length in particular) play a more significant role in determening the classification of an Iris flower than Sepal parameters. Let us try to visualise this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b17fe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Input Parameters')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 7]\n",
    "\n",
    "plt.bar(input_parameters.index,input_parameters.values)\n",
    "plt.title('Input Parameters Importance')\n",
    "plt.xlabel('Input Importance Score')\n",
    "plt.ylabel('Input Parameters')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a230dc",
   "metadata": {},
   "source": [
    "**Conclusion:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ce035",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook we have managed to build a classification model for the Iris Flower Dataset using the Random Forrest Algorithm by focusing on the Petal and Sepal features of the Iris Flower.The input parameters of the petal play a significant role in determining the classification prediction whilst the parameter of sepal width seems to be of little importance. According to the accuracy function and my own calculationsthe model produces an accurate prediction over 90% of the time.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
